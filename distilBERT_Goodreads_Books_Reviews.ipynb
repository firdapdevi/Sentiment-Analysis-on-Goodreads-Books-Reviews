{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwKjf0kNRbNu"
      },
      "source": [
        "# Goodreads Books Review Rating Prediction\n",
        "(https://www.kaggle.com/competitions/goodreads-books-reviews-290312/)\n",
        "---\n",
        "\n",
        "> Reviews are a good way to judge the quality of any product, whether it's books, clothes, technology, or anything else. When you want to buy something online these days, the first thing that comes to mind is the reviews from past buyers and the overall rating the product has received.\n",
        "\n",
        "> Reader feedback, whether positive or negative, five stars or one star, will encourage the product owner to make improvements.\n",
        "\n",
        "> Reader connection and engagement will be encouraged by book reviews, whether they be left on Amazon, Goodreads, or social media. Readers must determine whether or not other readers are enjoying the book.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tF1L9E3eSAl"
      },
      "source": [
        "Here are the columns of the dataset\n",
        "\n",
        "\n",
        "*   book_id - Id of Book\n",
        "\n",
        "*   review_id - Id of review\n",
        "\n",
        "*   rating - rating from 0 to 5\n",
        "\n",
        "*   review_text - review text\n",
        "\n",
        "*   date_added - date added\n",
        "\n",
        "*   date_updated - date updated\n",
        "\n",
        "*   read_at - read at\n",
        "\n",
        "\n",
        "*  started_at - started at\n",
        "\n",
        "\n",
        "*   n_votes - no. of votes\n",
        "\n",
        "\n",
        "*   n_comments - no. of comments\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model (BERT and Fine Tuning)**\n",
        "\n",
        "- BERT is not a finished model. It's designed to be fine-tuned to perform specific tasks like our sentiment analysis.\n",
        "\n",
        "- Fine-tuning takes the already pre-trained model and makes it perform a similar task, called a downstream task. Such downstream tasks need no architectural modification to the BERT model.\n",
        "\n",
        "- Google did the pre-training of BERT. It costs around $7,000 and ran for five days, using 16 TPUs. We can take advantage of that by using this pre-trained model.\n",
        "\n",
        "- Pre-trained models help to achieve better results in a shorter time with fewer costs.\n",
        "\n",
        "- We use DistilBERT, a smaller and faster version of BERT, by facilitating the Hugging Face Transformers package, a python library providing pre-trained NLP models."
      ],
      "metadata": {
        "id": "WrNNpJWET7bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author\n",
        "Firda Puspita Devi\n"
      ],
      "metadata": {
        "id": "30pi9ofd5Lkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Huggingface Transformers"
      ],
      "metadata": {
        "id": "14H60cJp5YH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "bBes2QpV5bYh",
        "outputId": "274a975e-beb1-4470-cf2b-6b3c6d5767a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN83339WK7mz"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Bootcamp/Day33 - Checkpoint 1')"
      ],
      "metadata": {
        "id": "OSNSuqPcJL8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Whh0_1t5KXdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "sys.path.append('../')\n",
        "os.chdir('../')\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import requests\n",
        "import re\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "from scipy.special import softmax\n",
        "\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import TFDistilBertForSequenceClassification\n",
        "\n",
        "import tensorflow as tf\n",
        "import json\n",
        "from io import StringIO"
      ],
      "metadata": {
        "id": "_KMB8F7OLp1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wordcloud matplotlib pandas"
      ],
      "metadata": {
        "id": "3Lqf69KSm2Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "id": "oCphL_lX_vU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration\n",
        "\n",
        "First, we'll need to enable GPUs for the notebook:\n",
        "\n",
        "Navigate to Editâ†’Notebook Settings\n",
        "select GPU from the Hardware Accelerator drop-down"
      ],
      "metadata": {
        "id": "eQYSBUm56M-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_gpus_available = len(tf.config.experimental.list_physical_devices('GPU'))\n",
        "print(\"Num GPUs Available: \", num_gpus_available)\n",
        "assert num_gpus_available > 0"
      ],
      "metadata": {
        "id": "chErPr016ZjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVY485HMKwP9"
      },
      "source": [
        "## Import data from Kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPypbf7-4u0-"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp \"/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/kaggle.json\" ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koHeyuxL4sPK"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c goodreads-books-reviews-290312"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfXTVBoBFcM3"
      },
      "outputs": [],
      "source": [
        "!unzip goodreads-books-reviews-290312.zip -d \"/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcU0c7bMhYFA"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsSbNA0Yh2NB"
      },
      "source": [
        "### Statistics summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5H6Q1WEpRsl"
      },
      "source": [
        "#### Limit to get only 10k records of train data or 1% of each rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmE8ghwTovqk"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/goodreads_train.csv\")\n",
        "\n",
        "total_records_needed = 10000\n",
        "\n",
        "# Calculate the total number of records for each rating\n",
        "rating_counts = data['rating'].value_counts()\n",
        "\n",
        "# Calculate 1% of each rank's total number\n",
        "rating_sample_sizes = (rating_counts * 0.01).astype(int)\n",
        "\n",
        "# Here we scale down the sample sizes proportionally if the sum exceeds 10.000\n",
        "if rating_sample_sizes.sum() > total_records_needed:\n",
        "    scaling_factor = total_records_needed / rating_sample_sizes.sum()\n",
        "    rating_sample_sizes = (rating_sample_sizes * scaling_factor).astype(int)\n",
        "\n",
        "\n",
        "# Sampling data according to calculated sample sizes\n",
        "samples = []\n",
        "for rating, size in rating_sample_sizes.items():\n",
        "    rating_samples = data[data['rating'] == rating].sample(n=size, random_state=1)\n",
        "    samples.append(rating_samples)\n",
        "\n",
        "# Concatenate all samples into a new DataFrame\n",
        "data = pd.concat(samples)\n",
        "\n",
        "\n",
        "print(rating_sample_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztnx4yVPpEfy"
      },
      "outputs": [],
      "source": [
        "# Validate the number of records and proportions\n",
        "print(\"Total records sampled:\", data.shape[0])\n",
        "print(data['rating'].value_counts(normalize=True))  # Check the percentage distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TM_7oywhaQdr"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKbUm5LqPqxK"
      },
      "outputs": [],
      "source": [
        "data_sum_stats = data.describe(include='all').T.drop('count', axis=1)\n",
        "data_sum_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COFlxVxqa2pA"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWPj1lA4arV1"
      },
      "outputs": [],
      "source": [
        "col_outlier = ['rating','n_votes','n_comments']\n",
        "\n",
        "for col in col_outlier:\n",
        "    plt.figure(figsize=(16, 4))\n",
        "\n",
        "    # histogram\n",
        "    plt.subplot(1, 3, 1)\n",
        "    sns.histplot(data[col], bins=30)\n",
        "    plt.title('Histogram')\n",
        "\n",
        "    # plot Q-Q\n",
        "    plt.subplot(1, 3, 2)\n",
        "    stats.probplot(data[col], dist=\"norm\", plot=plt)\n",
        "    plt.ylabel('Variable quantiles')\n",
        "\n",
        "    # box plot\n",
        "    plt.subplot(1, 3, 3)\n",
        "    sns.boxplot(y=data[col])\n",
        "    plt.title('Boxplot')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ykovy5wCSuHb"
      },
      "outputs": [],
      "source": [
        "# Select only numeric columns for correlation calculation\n",
        "numeric_train = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calculate the correlation matrix on just the numeric data\n",
        "corrMatrix = numeric_train.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.heatmap(corrMatrix, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlRj3WeWkUne"
      },
      "source": [
        "### Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb6VEivXkqOD"
      },
      "outputs": [],
      "source": [
        "# setting id as index column\n",
        "data.set_index(\"user_id\", inplace = True)\n",
        "data.set_index(\"book_id\", inplace = True)\n",
        "data.set_index(\"review_id\", inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD44b7IMl21z"
      },
      "source": [
        "#### Rating and Number of Votes Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0kIwge0c6GN"
      },
      "outputs": [],
      "source": [
        "# Calculate the average number of votes and comments per rating\n",
        "avg_data = data.groupby('rating')[['n_votes', 'n_comments']].mean().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6XSp2pIdEpE"
      },
      "outputs": [],
      "source": [
        "# Bar plot for train data\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='rating', y='n_votes', data=avg_data)\n",
        "plt.title('Average Number of Votes per Rating (Train Data)')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Average Number of Votes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKsNsGguo1lC"
      },
      "outputs": [],
      "source": [
        "# Bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='rating', y='n_comments', data=avg_data)\n",
        "plt.title('Average Number of Comments per Rating')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Average Number of Comments')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emmiIdvvdfEx"
      },
      "source": [
        "#### Number of Votes and Number of Comments Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrPebSuZGsbE"
      },
      "outputs": [],
      "source": [
        "# Check if there are any duplicate indices\n",
        "print(data.index.duplicated().sum())\n",
        "\n",
        "# If there are duplicates, reset the index\n",
        "if data.index.duplicated().any():\n",
        "    data.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNqO-YwSHMGP"
      },
      "outputs": [],
      "source": [
        "print(\"Max n_votes:\", data['n_votes'].max())\n",
        "print(\"Max n_comments:\", data['n_comments'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6kv9NH6St8w"
      },
      "outputs": [],
      "source": [
        "votes_bins = [0, 50, 100, 500, 1000, data['n_votes'].max() + 1]\n",
        "comments_bins = [0, 10, 50, 100, 500, data['n_comments'].max() + 1]\n",
        "\n",
        "print(\"Votes bins:\", votes_bins)\n",
        "print(\"Comments bins:\", comments_bins)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTfAEmyMIHYj"
      },
      "outputs": [],
      "source": [
        "# Check differences between bins to ensure they are all positive\n",
        "print(\"Votes bins differences:\", np.diff(votes_bins))\n",
        "print(\"Comments bins differences:\", np.diff(comments_bins))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGekMu7MIY8E"
      },
      "outputs": [],
      "source": [
        "# Manually set the last bin to be larger than any possible value in the dataset for both votes and comments\n",
        "votes_bins = [0, 50, 100, 500, 1000]\n",
        "comments_bins = [0, 10, 50, 100, 500]\n",
        "\n",
        "# Extend the last bin beyond the highest predefined value if necessary\n",
        "votes_bins.append(votes_bins[-1] + 500)\n",
        "comments_bins.append(comments_bins[-1] + 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeLPKBclIeAP"
      },
      "outputs": [],
      "source": [
        "# Apply binning again with corrected bins\n",
        "data['votes_bin'] = pd.cut(data['n_votes'], bins=votes_bins, right=False)\n",
        "data['comments_bin'] = pd.cut(data['n_comments'], bins=comments_bins, right=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzG5AFg0Igiw"
      },
      "outputs": [],
      "source": [
        "# Check new differences between bins to ensure all are positive\n",
        "print(\"New Votes bins differences:\", np.diff(votes_bins))\n",
        "print(\"New Comments bins differences:\", np.diff(comments_bins))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGkzKpCbmDyk"
      },
      "outputs": [],
      "source": [
        "avg_comments_per_vote_bin = data.groupby('votes_bin')['n_comments'].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='votes_bin', y='n_comments', data=avg_comments_per_vote_bin)\n",
        "plt.title('Average Number of Comments per Vote Bins')\n",
        "plt.xlabel('Number of Votes (binned)')\n",
        "plt.ylabel('Average Number of Comments')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WordCloud"
      ],
      "metadata": {
        "id": "O_rM62fUnihX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(review for review in data['review_text'])\n",
        "\n",
        "# Generate a word cloud image\n",
        "wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate(text)\n",
        "\n",
        "# Display the word cloud image:\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GG44MPLwnrOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top N Words"
      ],
      "metadata": {
        "id": "lqCl7pTmoBUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "words = text.split()\n",
        "\n",
        "# Get frequencies of each word\n",
        "word_counts = Counter(words)\n",
        "\n",
        "# Determine the number of top words to display, e.g., top 10\n",
        "top_n = 10\n",
        "top_words = word_counts.most_common(top_n)\n",
        "top_words_df = pd.DataFrame(top_words, columns=['Word', 'Frequency'])\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(top_words_df['Word'], top_words_df['Frequency'], color ='blue')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top N Words in the Dataset')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9jcKc_eNn1_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIYAzWfnlRCg"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxspuNNImAp_"
      },
      "source": [
        "### **Label anotator sentiment**\n",
        "\n",
        "To insert labels such as 'positive', 'neutral', or 'negative' for the DataFrame, we would typically go through a sentiment analysis process. This can be done either:\n",
        "\n",
        "\n",
        "**1. Manually by reading through each text and assigning a label based on the sentiment conveyed**\n",
        "\n",
        "For manual labeling, we could create a new column in the DataFrame and insert the labels directly.\n",
        "\n",
        "\n",
        "**2. Automatically using a sentiment analysis tool or model**\n",
        "\n",
        "For automatic labeling, we'd typically use a pre-trained sentiment analysis model from a library like NLTK, TextBlob, or through a service like Google Cloud Natural Language API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FihcRihj-r_"
      },
      "outputs": [],
      "source": [
        "def assign_sentiment_from_rating(rating):\n",
        "    # Assign sentiment based on rating\n",
        "    if rating in [4, 5]:\n",
        "        return 'positive'\n",
        "    elif rating in [0, 1, 2]:\n",
        "        return 'negative'\n",
        "    elif rating == 3:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'undefined'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUZFimN9xUTS"
      },
      "outputs": [],
      "source": [
        "data['sentiment'] = data['rating'].apply(assign_sentiment_from_rating)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ1XXZxqxXfr"
      },
      "outputs": [],
      "source": [
        "print(data[['rating', 'sentiment']].tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzh6Zx8Kxtd_"
      },
      "source": [
        "### Preprocess text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0kHrYioMn8A"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oisgpKrFxopt"
      },
      "outputs": [],
      "source": [
        "# Specify columns to delete\n",
        "columns_to_delete = ['date_added', 'date_updated', 'read_at', 'started_at',\n",
        "                     'n_votes', 'n_comments', 'votes_bin', 'comments_bin',\n",
        "                     'rating']\n",
        "\n",
        "data = data.drop(columns=columns_to_delete)\n",
        "\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "# common functions\n",
        "###\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "def count_param(module, trainable=False):\n",
        "    if trainable:\n",
        "        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "    else:\n",
        "        return sum(p.numel() for p in module.parameters())\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def metrics_to_string(metric_dict):\n",
        "    string_list = []\n",
        "    for key, value in metric_dict.items():\n",
        "        string_list.append('{}:{:.2f}'.format(key, value))\n",
        "    return ' '.join(string_list)"
      ],
      "metadata": {
        "id": "gcXUYraxyoiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "set_seed(20052024)"
      ],
      "metadata": {
        "id": "LwJ3QljsysnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7aYfXnlxoSR"
      },
      "outputs": [],
      "source": [
        "def cleaning_text(text):\n",
        "    # remove url\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    text = url_pattern.sub(r'', text)\n",
        "\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    text = re.sub(r'#', '', text)\n",
        "\n",
        "    # remove mention handle user (@)\n",
        "    text = re.sub(r'@[\\w]*', ' ', text)\n",
        "\n",
        "    # remove emojis\n",
        "    emoji_pattern = re.compile(\n",
        "        '['\n",
        "        '\\U0001F600-\\U0001F64F'  # emoticons\n",
        "        '\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
        "        '\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
        "        '\\U0001F700-\\U0001F77F'  # alchemical symbols\n",
        "        '\\U0001F780-\\U0001F7FF'  # Geometric Shapes Extended\n",
        "        '\\U0001F800-\\U0001F8FF'  # Supplemental Arrows-C\n",
        "        '\\U0001F900-\\U0001F9FF'  # Supplemental Symbols and Pictographs\n",
        "        '\\U0001FA00-\\U0001FA6F'  # Chess Symbols\n",
        "        '\\U0001FA70-\\U0001FAFF'  # Symbols and Pictographs Extended-A\n",
        "        '\\U00002702-\\U000027B0'  # Dingbats\n",
        "        '\\U000024C2-\\U0001F251'\n",
        "        ']+',\n",
        "        flags=re.UNICODE\n",
        "    )\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "\n",
        "    # remove punctuation\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    for x in text.lower():\n",
        "        if x in punctuations:\n",
        "            text = text.replace(x, \" \")\n",
        "\n",
        "    # remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# CONSTRUCT STOPWORDS\n",
        "alir3z4_stopword = \"https://github.com/Alir3z4/stop-words/blob/master/english.txt\"\n",
        "iso_stopword = \"https://github.com/stopwords-iso/stopwords-en/blob/master/stopwords-en.txt\"\n",
        "bbalet_stopword = \"https://github.com/bbalet/stopwords/blob/master/_stopwords.txt\"\n",
        "igorbrigadir_stopword = \"https://github.com/igorbrigadir/stopwords/blob/master/en/terrier.txt\"\n",
        "naimdjon_stopword = \"https://github.com/naimdjon/stopwords/blob/master/stopwords.txt\"\n",
        "saurabbhsp_stopword = \"https://github.com/saurabbhsp/stopwords/blob/master/English.txt\"\n",
        "sanjaalcorps_stopword = \"https://github.com/sanjaalcorps/EnglishStopWords/blob/master/stop_words_eng.csv\"\n",
        "cihanhelin_stopword = \"https://github.com/cihanhelin/NLTK-s-list-of-english-stopwords/blob/main/NLTK-s-list-of-english-stopwords\"\n",
        "machouz1_stopword = \"https://github.com/machouz/stopwords/blob/master/stopwords/stop-words_english_1_en.txt\"\n",
        "machouz2_stopword = \"https://github.com/machouz/stopwords/blob/master/stopwords/stop-words_english_2_en.txt\"\n",
        "machouz3_stopword = \"https://github.com/machouz/stopwords/blob/master/stopwords/stop-words_english_3_en.txt\"\n",
        "machouz4_stopword = \"https://github.com/machouz/stopwords/blob/master/stopwords/stop-words_english_4_google_en.txt\"\n",
        "machouz5_stopword = \"https://github.com/machouz/stopwords/blob/master/stopwords/stop-words_english_5_en.txt\"\n",
        "machouz6_stopword = \"https://github.com/machouz/stopwords/blob/master/stopwords/stop-words_english_6_en.txt\"\n",
        "nltk_stopword = stopwords.words('english')\n",
        "\n",
        "# create path url for each stopword\n",
        "path_stopwords = [alir3z4_stopword, iso_stopword, bbalet_stopword, igorbrigadir_stopword,\n",
        "                  naimdjon_stopword, saurabbhsp_stopword, sanjaalcorps_stopword, cihanhelin_stopword,\n",
        "                  machouz1_stopword, machouz2_stopword, machouz3_stopword, machouz4_stopword,\n",
        "                  machouz5_stopword, machouz6_stopword]\n",
        "\n",
        "# combine stopwords\n",
        "stopwords_l = nltk_stopword\n",
        "for path in path_stopwords:\n",
        "    response = requests.get(path)\n",
        "    stopwords_l += response.text.split('\\n')\n",
        "\n",
        "custom_st = '''\n",
        "A fun, fast paced science fiction thriller. I read it in 2 nights and couldn't put it down.\n",
        "The book is about the quantum theory of many worlds which states that all decisions we make\n",
        "throughout our lives basically create branches,\n",
        "and that each possible path through the decision tree can be thought of as a parallel world.\n",
        "And in this book, someone invents a way to switch between these worlds.\n",
        "This was nicely alluded to/foreshadowed in this quote: \\n\n",
        "\"I think about all the choices we've made that created this moment.\n",
        "Us sitting here together at this beautiful table.\n",
        "Then I think of all the possible events that could have stopped this moment from ever happening,\n",
        "and it all feels, I don't know...\" \"What?\" \"So fragile.\"\n",
        "Now he becomes thoughtful for a moment. He says finally,\n",
        "\"It's terrifying when you consider that every thought we have, every choice we could possibly make,\n",
        "branches into a new world.\" \\n (view spoiler)\n",
        "[This book can't be discussed without spoilers. It is a book about choice and regret.\n",
        "Ever regret not chasing the girl of your dreams so you can focus on your career?\n",
        "Well Jason2 made that choice and then did regret it. Clearly the author is trying to tell us to optimize for happiness -\n",
        "to be that second rate physics teacher at a community college if it means you can have a happy life.\n",
        "I'm being snarky because while there is certainly something to that, you also have to have meaning in your life that comes from within.\n",
        "I thought the book was a little shallow on this dimension. In fact, all the characters were fairly shallow.\n",
        "Daniela was the perfect wife. Ryan the perfect antithesis of Jason. Amanda the perfect loyal traveling companion, etc.\n",
        "This, plus the fact that the book was weak on the science are what led me to take a few stars off -\n",
        "but I'd still read it again if I could go back in time - was a very fun and engaging read. \\n\n",
        "If you want to really minimize regret, you have to live your life to avoid it in the first place.\n",
        "Regret can't be hacked, which is kind of the point of the book.\n",
        "My favorite book about regret is Remains of the Day. I do really like the visualization of the decision tree though - that is a powerful concept. \\n\n",
        "\"Every moment, every breath, contains a choice. But life is imperfect. We make the wrong choices. So we end up living in a state of perpetual regret,\n",
        "and is there anything worse? I built something that could actually eradicate regret. Let you find worlds where you made the right choice.\"\n",
        "Daniela says, \"Life doesn't work that way. You live with your choices and learn. You don't cheat the system.\n",
        "'''\n",
        "\n",
        "# create dictionary with unique stopword\n",
        "st_words = set(stopwords_l)\n",
        "custom_stopword = set(custom_st.split())\n",
        "\n",
        "# result stopwords\n",
        "stop_words = st_words | custom_stopword\n",
        "print(f'Stopwords: {list(stop_words)[:5]}')\n",
        "# remove stopwords\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "\n",
        "def remove_stopword(text, stop_words=stop_words):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "    return ' '.join(filtered_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrFXyawkzMXS"
      },
      "outputs": [],
      "source": [
        "# pipeline preprocess\n",
        "def preprocess(text):\n",
        "    # cleaning text and lowercase\n",
        "    output = cleaning_text(text)\n",
        "\n",
        "    # remove stopwords\n",
        "    output = remove_stopword(output)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvHQ2erwzP47"
      },
      "outputs": [],
      "source": [
        "# implement preprocessing\n",
        "\n",
        "# Copy the datasets\n",
        "preprocessed_data = data.copy()\n",
        "\n",
        "# Apply the preprocessing function\n",
        "preprocessed_data['review_text'] = data['review_text'].map(preprocess)\n",
        "\n",
        "print(preprocessed_data['review_text'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt_3JluxzRfc"
      },
      "outputs": [],
      "source": [
        "# Define file paths\n",
        "csv_file_path = '/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/preprocessed_data.csv'\n",
        "\n",
        "# Save the train dataset\n",
        "df = pd.DataFrame(preprocessed_data)\n",
        "df.to_csv(csv_file_path, sep=';', index=False, header=True)\n",
        "print(f'Preprocessed data has been saved to {csv_file_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqJ9wrM-zYDB"
      },
      "outputs": [],
      "source": [
        "# load processed dataset into pandas\n",
        "preprocessed_data = pd.read_csv('/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/preprocessed_data.csv', sep=';')\n",
        "preprocessed_data.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data[preprocessed_data['sentiment'] == \"neutral\"]"
      ],
      "metadata": {
        "id": "Q3FBBMuU9H15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zearyHpFkNFr"
      },
      "outputs": [],
      "source": [
        "texts = preprocessed_data['review_text'].tolist()\n",
        "labels = preprocessed_data['sentiment'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3IYDxtOz_3l"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load distilbert-base-multilingual-cased-sentiments-student"
      ],
      "metadata": {
        "id": "-pmyxhmiUPoa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVILC6EW0B8x"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
        "\n",
        "# # Check if GPU is available and move the model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "vWuL6rYEUsR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_param(model)"
      ],
      "metadata": {
        "id": "bUqrmjDIUtD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Preparing the Input and Making Predictions"
      ],
      "metadata": {
        "id": "d0aulQZtUeou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/preprocessed_data.csv'\n",
        "df = pd.read_csv(file_path, sep=',')\n",
        "\n",
        "# Split the dataset into train, test, and validation sets\n",
        "train_df, test_valid_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "test_df, valid_df = train_test_split(test_valid_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Save the splits as TSV files\n",
        "train_df.to_csv('/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/train.tsv', sep='\\t', index=False)\n",
        "test_df.to_csv('/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/test.tsv', sep='\\t', index=False)\n",
        "valid_df.to_csv('/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/valid.tsv', sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "fKc7XwS3UdMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_path = '/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/train.tsv'\n",
        "valid_dataset_path = '/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/valid.tsv'\n",
        "test_dataset_path = '/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/train.tsv'"
      ],
      "metadata": {
        "id": "Z3Ee6rNwU2Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Set up label mappings"
      ],
      "metadata": {
        "id": "T6umhbG82AWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL2INDEX = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "INDEX2LABEL = {0: 'negative', 1: 'neutral', 2: 'positive'}"
      ],
      "metadata": {
        "id": "270OMzTuBfmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from TSV files into pandas DataFrames\n",
        "train_df = pd.read_csv(train_dataset_path, delimiter=';')\n",
        "valid_df = pd.read_csv(valid_dataset_path, delimiter=';')\n",
        "test_df = pd.read_csv(test_dataset_path, delimiter=';')"
      ],
      "metadata": {
        "id": "dAzlsGi_30zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert textual labels to numeric labels using LABEL2INDEX\n",
        "train_df['label'] = train_df['sentiment'].map(LABEL2INDEX).astype(int)\n",
        "valid_df['label'] = valid_df['sentiment'].map(LABEL2INDEX).astype(int)\n",
        "test_df['label'] = test_df['sentiment'].map(LABEL2INDEX).astype(int)"
      ],
      "metadata": {
        "id": "hrMSGY8l36_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from transformers import AutoTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Ensure text is a string and handle NaN values\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)\n",
        "        if pd.isna(label):\n",
        "            label = 0  # Default label\n",
        "\n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_dataset = SentimentDataset(train_df['review_text'], train_df['label'].map(LABEL2INDEX), tokenizer, max_len=512)\n",
        "valid_dataset = SentimentDataset(valid_df['review_text'], valid_df['label'].map(LABEL2INDEX), tokenizer, max_len=512)\n",
        "test_dataset = SentimentDataset(test_df['review_text'], test_df['label'].map(LABEL2INDEX), tokenizer, max_len=512)\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=6, shuffle=True, num_workers=4)  # Reduced batch size\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=6, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=6, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "_3GDqcfN1cEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2i, i2w = LABEL2INDEX, INDEX2LABEL\n",
        "print(w2i)\n",
        "print(i2w)"
      ],
      "metadata": {
        "id": "xVbh2qrSXNF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test model on sample sentences"
      ],
      "metadata": {
        "id": "W4Ap7W4W8RBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Example text\n",
        "text = '1 star highlander historical romance.'\n",
        "\n",
        "# Tokenize the text\n",
        "subwords = tokenizer.encode(text, return_tensors='pt').to(model.device)\n",
        "\n",
        "# Get the logits from the model\n",
        "output = model(subwords)\n",
        "logits = output.logits\n",
        "\n",
        "# Print the shape of logits for debugging\n",
        "print(f\"Shape of logits: {logits.shape}\")\n",
        "\n",
        "# Get the top label and its confidence\n",
        "topk = torch.topk(logits, k=1, dim=-1)\n",
        "label = topk[1].squeeze(dim=-1).item()\n",
        "confidence = F.softmax(logits, dim=-1).squeeze()[label] * 100\n",
        "\n",
        "# Print the result\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({confidence:.3f}%)')"
      ],
      "metadata": {
        "id": "Qq-z4iBq8YWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'started interesting thriller woman run mysterious pass story took strange twists turns ends talky talky reveal.'\n",
        "\n",
        "# Tokenize the text\n",
        "subwords = tokenizer.encode(text, return_tensors='pt').to(model.device)\n",
        "\n",
        "# Get the logits from the model\n",
        "output = model(subwords)\n",
        "logits = output.logits\n",
        "\n",
        "# Print the shape of logits for debugging\n",
        "print(f\"Shape of logits: {logits.shape}\")\n",
        "\n",
        "# Get the top label and its confidence\n",
        "topk = torch.topk(logits, k=1, dim=-1)\n",
        "label = topk[1].squeeze(dim=-1).item()\n",
        "confidence = F.softmax(logits, dim=-1).squeeze()[label] * 100\n",
        "\n",
        "# Print the result\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({confidence:.3f}%)')\n"
      ],
      "metadata": {
        "id": "hjTCZaH88lBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine tuning & evaluation"
      ],
      "metadata": {
        "id": "NdYWCwHH-Ia_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ],
      "metadata": {
        "id": "XcmqFVCo8YuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "29qUtGZ2-Nw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "rI-rvJhV-OTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Y4Q3w_oTMNqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=3e-6)\n",
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "QpdTRqNrI5QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training distilbert-base-multilingual-cased-sentiments-student for Sentiment Analysis"
      ],
      "metadata": {
        "id": "C0yO8gE5-jqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dropna(subset=['label'], inplace=True)"
      ],
      "metadata": {
        "id": "6chdFYnHC4GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaN values in the DataFrame\n",
        "print(\"NaN in texts:\", train_df['review_text'].isna().sum())\n",
        "print(\"NaN in labels:\", train_df['label'].isna().sum())\n",
        "\n",
        "# Drop rows where any of the necessary columns are NaN\n",
        "train_df.dropna(subset=['review_text', 'label'], inplace=True)\n"
      ],
      "metadata": {
        "id": "iqzceuLJKKVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load the Model and Optimizer"
      ],
      "metadata": {
        "id": "StCH44LoprYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "model.to('cuda')\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Function to get learning rate\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "metadata": {
        "id": "ggf2j9Ko-a3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define forward_sequence_classification Function"
      ],
      "metadata": {
        "id": "YCYk-QRSp1SK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the forward function\n",
        "def forward_sequence_classification(model, batch_data, i2w, device):\n",
        "    input_ids = batch_data['input_ids'].to(device)\n",
        "    attention_mask = batch_data['attention_mask'].to(device)\n",
        "    labels = batch_data['labels'].to(device)\n",
        "\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "    loss = outputs.loss\n",
        "    logits = outputs.logits\n",
        "\n",
        "    batch_hyp = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "    batch_label = labels.cpu().numpy()\n",
        "\n",
        "    return loss, batch_hyp, batch_label"
      ],
      "metadata": {
        "id": "iCxKAW5ppnds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define metrics calculation functions"
      ],
      "metadata": {
        "id": "-i4MGfbCp5MK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "metrics calculation functions"
      ],
      "metadata": {
        "id": "6SITMXgaqkfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "# Define the metrics calculation functions\n",
        "def document_sentiment_metrics_fn(predictions, labels):\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n"
      ],
      "metadata": {
        "id": "uUDd4WEJp9fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "metrics to string functions"
      ],
      "metadata": {
        "id": "1fibNGWeqpBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_to_string(metrics):\n",
        "    return \"Acc: {:.4f}, Prec: {:.4f}, Rec: {:.4f}, F1: {:.4f}\".format(\n",
        "        metrics['accuracy'],\n",
        "        metrics['precision'],\n",
        "        metrics['recall'],\n",
        "        metrics['f1']\n",
        "    )\n"
      ],
      "metadata": {
        "id": "N_Oe8wZPqgwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training and evaluation loop"
      ],
      "metadata": {
        "id": "WY2XYgYcqEhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "n_epochs = 10\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    torch.set_grad_enabled(True)\n",
        "\n",
        "    total_train_loss = 0\n",
        "    list_hyp, list_label = [], []\n",
        "\n",
        "    train_pbar = tqdm(train_loader, leave=True, total=len(train_loader))\n",
        "    for i, batch_data in enumerate(train_pbar):\n",
        "        # Forward model\n",
        "        loss, batch_hyp, batch_label = forward_sequence_classification(model, batch_data, i2w=i2w, device='cuda')\n",
        "\n",
        "        # Update model\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        tr_loss = loss.item()\n",
        "        total_train_loss += tr_loss\n",
        "\n",
        "        # Calculate metrics\n",
        "        list_hyp += list(batch_hyp)\n",
        "        list_label += list(batch_label)\n",
        "\n",
        "        train_pbar.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f}\".format(\n",
        "            (epoch+1), total_train_loss/(i+1), get_lr(optimizer)\n",
        "        ))\n",
        "\n",
        "    # Calculate train metric\n",
        "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "    print(\"(Epoch {}) TRAIN LOSS:{:.4f} {} LR:{:.8f}\".format(\n",
        "        (epoch+1), total_train_loss/(i+1), metrics_to_string(metrics), get_lr(optimizer)\n",
        "    ))\n",
        "\n",
        "    # Evaluate on validation\n",
        "    model.eval()\n",
        "    torch.set_grad_enabled(False)\n",
        "\n",
        "    total_loss, total_correct, total_labels = 0, 0, 0\n",
        "    list_hyp, list_label = [], []\n",
        "\n",
        "    pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n",
        "    for i, batch_data in enumerate(pbar):\n",
        "        loss, batch_hyp, batch_label = forward_sequence_classification(model, batch_data, i2w=i2w, device='cuda')\n",
        "\n",
        "        # Calculate total loss\n",
        "        valid_loss = loss.item()\n",
        "        total_loss += valid_loss\n",
        "\n",
        "        # Calculate evaluation metrics\n",
        "        list_hyp += list(batch_hyp)\n",
        "        list_label += list(batch_label)\n",
        "        metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "\n",
        "        pbar.set_description(\"VALID LOSS:{:.4f} {}\".format(total_loss/(i+1), metrics_to_string(metrics)))\n",
        "\n",
        "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "    print(\"(Epoch {}) VALID LOSS:{:.4f} {}\".format((epoch+1), total_loss/(i+1), metrics_to_string(metrics)))\n"
      ],
      "metadata": {
        "id": "rQoR2rLfwOIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test\n",
        "model.eval()\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "list_hyp = []\n",
        "\n",
        "pbar = tqdm(test_loader, leave=True, total=len(test_loader))\n",
        "for i, batch_data in enumerate(pbar):\n",
        "    _, batch_hyp, _ = forward_sequence_classification(model, batch_data, i2w=LABEL2INDEX, device='cuda')\n",
        "    list_hyp += list(batch_hyp)\n",
        "\n",
        "# Save predictions to a file\n",
        "df = pd.DataFrame({'label': list_hyp}).reset_index()\n",
        "df.to_csv('pred.txt', index=False)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "5XLIkoFT1xxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/distilbert_base_multilingual_model.pth')"
      ],
      "metadata": {
        "id": "WI6lvV5X-6ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test fine-tuned model on sample sentences"
      ],
      "metadata": {
        "id": "HtLSuzbI12Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Example text\n",
        "text = '1 star highlander historical romance.'\n",
        "\n",
        "# Tokenize the text\n",
        "subwords = tokenizer.encode(text, return_tensors='pt').to(model.device)\n",
        "\n",
        "# Get the logits from the model\n",
        "output = model(subwords)\n",
        "logits = output.logits\n",
        "\n",
        "# Print the shape of logits for debugging\n",
        "print(f\"Shape of logits: {logits.shape}\")\n",
        "\n",
        "# Get the top label and its confidence\n",
        "topk = torch.topk(logits, k=1, dim=-1)\n",
        "label = topk[1].squeeze(dim=-1).item()\n",
        "confidence = F.softmax(logits, dim=-1).squeeze()[label] * 100\n",
        "\n",
        "# Print the result\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({confidence:.3f}%)')"
      ],
      "metadata": {
        "id": "cwA9emMt-bIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'started interesting thriller woman run mysterious pass story took strange twists turns ends talky talky reveal.'\n",
        "\n",
        "# Tokenize the text\n",
        "subwords = tokenizer.encode(text, return_tensors='pt').to(model.device)\n",
        "\n",
        "# Get the logits from the model\n",
        "output = model(subwords)\n",
        "logits = output.logits\n",
        "\n",
        "# Print the shape of logits for debugging\n",
        "print(f\"Shape of logits: {logits.shape}\")\n",
        "\n",
        "# Get the top label and its confidence\n",
        "topk = torch.topk(logits, k=1, dim=-1)\n",
        "label = topk[1].squeeze(dim=-1).item()\n",
        "confidence = F.softmax(logits, dim=-1).squeeze()[label] * 100\n",
        "\n",
        "# Print the result\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({confidence:.3f}%)')\n"
      ],
      "metadata": {
        "id": "LE1Z4hr_2N8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'An interesting retelling of Snow White.'\n",
        "\n",
        "# Tokenize the text\n",
        "subwords = tokenizer.encode(text, return_tensors='pt').to(model.device)\n",
        "\n",
        "# Get the logits from the model\n",
        "output = model(subwords)\n",
        "logits = output.logits\n",
        "\n",
        "# Print the shape of logits for debugging\n",
        "print(f\"Shape of logits: {logits.shape}\")\n",
        "\n",
        "# Get the top label and its confidence\n",
        "topk = torch.topk(logits, k=1, dim=-1)\n",
        "label = topk[1].squeeze(dim=-1).item()\n",
        "confidence = F.softmax(logits, dim=-1).squeeze()[label] * 100\n",
        "\n",
        "# Print the result\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({confidence:.3f}%)')\n"
      ],
      "metadata": {
        "id": "xjEk8tPgI46p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "mzCRfPWw5YI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "id": "Ib2Kt3I05drl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Define hyperparameters to be tuned\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 5e-5)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [4, 6, 8])\n",
        "\n",
        "    # Initialize the model\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "    model.to('cuda')\n",
        "\n",
        "    # Initialize the optimizer\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    # Dataloaders with the new batch size\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Training loop\n",
        "    n_epochs = 3  # Use a smaller number of epochs for hyperparameter tuning\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "        total_train_loss = 0\n",
        "        list_hyp, list_label = [], []\n",
        "\n",
        "        train_pbar = tqdm(train_loader, leave=True, total=len(train_loader))\n",
        "        for i, batch_data in enumerate(train_pbar):\n",
        "            # Forward model\n",
        "            loss, batch_hyp, batch_label = forward_sequence_classification(model, batch_data, device='cuda')\n",
        "\n",
        "            # Update model\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_loss = loss.item()\n",
        "            total_train_loss += tr_loss\n",
        "\n",
        "            # Calculate metrics\n",
        "            list_hyp += list(batch_hyp)\n",
        "            list_label += list(batch_label)\n",
        "\n",
        "            train_pbar.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f}\".format(\n",
        "                (epoch+1), total_train_loss/(i+1), lr\n",
        "            ))\n",
        "\n",
        "        # Evaluate on validation\n",
        "        model.eval()\n",
        "        torch.set_grad_enabled(False)\n",
        "\n",
        "        total_loss, total_correct, total_labels = 0, 0, 0\n",
        "        list_hyp, list_label = [], []\n",
        "\n",
        "        pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n",
        "        for i, batch_data in enumerate(pbar):\n",
        "            loss, batch_hyp, batch_label = forward_sequence_classification(model, batch_data, device='cuda')\n",
        "\n",
        "            # Calculate total loss\n",
        "            valid_loss = loss.item()\n",
        "            total_loss += valid_loss\n",
        "\n",
        "            # Calculate evaluation metrics\n",
        "            list_hyp += list(batch_hyp)\n",
        "            list_label += list(batch_label)\n",
        "            metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "\n",
        "            pbar.set_description(\"VALID LOSS:{:.4f} {}\".format(total_loss/(i+1), metrics_to_string(metrics)))\n",
        "\n",
        "    # Return the main metric to optimize\n",
        "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "    return metrics['f1']\n",
        "\n",
        "# Set up the Optuna study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# Print best hyperparameters\n",
        "print(\"Best hyperparameters: \", study.best_params)\n",
        "\n",
        "# Save the study\n",
        "study.trials_dataframe().to_csv('/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/optuna_study.csv')\n",
        "\n",
        "# Save the best model\n",
        "best_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "best_model.to('cuda')\n",
        "best_optimizer = AdamW(best_model.parameters(), lr=study.best_params['lr'])\n",
        "torch.save(best_model, '/content/drive/MyDrive/Bootcamp/Day 33 - Checkpoint 1/best_distilbert_model.pth')\n"
      ],
      "metadata": {
        "id": "8TDMIHVS506r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1G4-jB9G6bla"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}